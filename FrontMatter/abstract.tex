\setlength{\parindent}{0pt}

This dissertation rigorously explores the efficacy of machine learning-based Network Intrusion Detection Systems (NIDS) in identifying cyber threats through pattern analysis in network traffic data. The research methodology involves a detailed examination of the transferability of patterns learned by Random Forest and Support Vector Machine (SVM) classifiers across the CTU13 and CICIDS2017 datasets, thereby assessing the adaptability of models trained on one dataset to detect attacks in another. The study evaluates flow-based features to differentiate between malicious and benign traffic and employs the SHAP explainable AI technique to pinpoint the most critical features for threat detection.

The novelty lies in the comprehensive investigation of model transferability in NIDS and the application of explainable AI to provide insights into the classifiers' decision-making process. The findings highlight challenges posed by dataset biases and limitations of directly applying models across datasets. The proposed strategies for improving detection accuracy and model interpretability can significantly enhance NIDS robustness and effectiveness against evolving cyber threats. This work advances machine learning-based cybersecurity solutions by providing insights into the transferability of learned patterns and critical factors influencing NIDS performance across diverse network environments.