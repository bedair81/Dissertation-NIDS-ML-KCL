\chapter{Implementation}\label{chap:implementation}

This chapter provides a comprehensive overview of the experiments conducted in this dissertation, detailing the experimental setup, dataset usage, and the design of each experiment. We also explore the implementation of key package modules, accompanied by relevant code excerpts highlighting essential functionality.

\section{Experiment Implementation}\label{sec:ExperimentImplementation}

The experiments in this dissertation involve training and evaluating three classifiers: a Dummy Classifier, a Random Forest Classifier, and a Support Vector Machine (SVM) Classifier. Each classifier is trained on both the CICIDS2017~\cite{sharafaldin2018toward} and CTU13~\cite{garcia2014empirical} datasets and tested on both the CICIDS2017 and CTU13 datasets to assess transferability and generalisation capabilities.

Initially, we set up the experiments using scikit-learn's classifier implementations. However, due to the extensive training times required for the CPU-based models, we decided to switch to CUML's GPU-accelerated models~\cite{raschka2020machine}. The CUML library provides GPU-accelerated machine learning algorithms, enabling faster training and inference times. By leveraging the power of GPUs, we can significantly accelerate the training process, making it more feasible to train complex models on large datasets. The benefits of using CUML's GPU-accelerated models include reduced training times, improved scalability, and the ability to handle larger datasets efficiently.

The choice of Random Forest and SVM classifiers is justified by their proven effectiveness in handling large, high-dimensional datasets and unbalanced class distributions~\cite{farnaaz2016random, teng2017svm}, which are common in network traffic classification, as discussed in Chapter~\ref{chap:background}, Section~\ref{sec:classifiers}. The CTU13 and CICIDS2017 datasets exhibit such class imbalances (Tables~\ref{tab:ctu13_breakdown} and~\ref{tab:cicids2017_breakdown}), making these classifiers well-suited for this study. We employ the SHAP library~\cite{lundberg2017unified} for explainability due to its ability to provide insights into the decision-making process of machine learning models and identify essential features, as highlighted in Chapter~\ref{chap:background}, Section~\ref{sec:explainable}.

\subsection{Data Pre-processing}\label{subsec:pre-processing}

Proper data preprocessing is crucial for ensuring the effectiveness of the trained classifiers. The relabelling scripts, \texttt{relabelCICIDS2017.py} (Algorithm~\ref{alg:relabelCICIDS2017}) and \texttt{relabelCTU13.py} (Algorithm~\ref{alg:relabelCTU13}), standardise feature names and class labels across the datasets. This process involves mapping dataset features to a consistent naming convention, removing features unique to one dataset to avoid overfitting, and ensuring class labels are compatible, as described in Chapter~\ref{chap:specification-design}, Section~\ref{subsec:DataPreprocessing}. For example, the CTU13 dataset's binary labels '0' and '1' are converted to 'Benign' and 'Botnet' to match the CICIDS2017 labelling scheme.

During the preprocessing stage, several data quality issues and inconsistencies were encountered, such as missing values and differing feature names across datasets. We addressed these issues through careful data cleaning, imputation, and feature mapping techniques to ensure the datasets' compatibility and integrity, aligning with the challenges discussed in Chapter~\ref{chap:relevant-work}, Section~\ref{sec:ChallengesLimitations}.

\subsection{Experiment 1: Dummy Classifier}\label{subsec:baseline-performance}

The Dummy Classifier from the scikit-learn library~\cite{pedregosa2011scikit} serves as a baseline for evaluating the performance of the more advanced classifiers. It predicts the most frequent class in the training data. We trained three Dummy Classifiers (Algorithm~\ref{alg:trainDummyClassifier}): one on the CTU13 dataset for binary classification and two on the CICIDS2017 dataset for binary and multiclass classification. The Dummy Classifiers use the same features as the Random Forest and SVM classifiers, and their performance metrics (accuracy, precision, recall, and F1 score) provide a baseline for comparison, as discussed in Chapter~\ref{chap:specification-design}, Section~\ref{subsec:DummyClassifier}.

\subsection{Experiment 2: Random Forest Classifier}\label{subsec:random-forest-classifier}

Random Forest, an ensemble learning method constructing multiple decision trees~\cite{hastie2009random}, is well-suited for handling large, high-dimensional datasets and unbalanced class distributions~\cite{farnaaz2016random}, which are common in network traffic classification. The CTU13 and CICIDS2017 datasets exhibit such class imbalances (Tables~\ref{tab:ctu13_breakdown} and~\ref{tab:cicids2017_breakdown}), as discussed in Chapter~\ref{chap:background}, Section~\ref{sec:datasets}.

Three Random Forest Classifiers were trained (\texttt{trainRandomForest.ipynb}, Algorithm~\ref{alg:trainRandomForest}): one on the CTU13 dataset and two on the CICIDS2017 dataset for binary and multiclass classification. The classifiers are evaluated on their respective datasets and then tested on the other dataset to assess transferability, addressing RQ1, as discussed in Chapter~\ref{chap:specification-design}, Section~\ref{subsec:RandomForest_SVMClassifier}. The SHapley Additive exPlanations (SHAP) library~\cite{lundberg2017unified} is employed to explain the classifiers' predictions and identify the essential features, contributing to the interpretability and transparency of the models, as highlighted in Chapter~\ref{chap:relevant-work}, Section~\ref{sec:ExplainableAITechniques}.

\subsection{Experiment 3: Support Vector Machine Classifier}\label{subsec:support-vector-machine-classifier}

Support Vector Machines (SVMs) effectively handle large, high-dimensional, non-linear data~\cite{cortes1995support, scholkopf2002learning}. They have been successfully applied to network intrusion detection tasks~\cite{kim2003network, teng2017svm}, as discussed in Chapter~\ref{chap:relevant-work}, Section~\ref{sec:SVMIntrusion}.

The experimental setup for the SVM Classifiers (\texttt{trainSVM.ipynb}, Algorithm~\ref{alg:trainSVM}) mirrors that of the Random Forest Classifiers: we trained three SVMs on the CTU13 and CICIDS2017 datasets, which are then evaluated on their respective datasets, and tested on the other dataset, addressing the transferability and generalisability aspects of RQ1, as discussed in Chapter~\ref{chap:specification-design}, Section~\ref{subsec:RandomForest_SVMClassifier}. SHAP is used to interpret the SVM predictions and identify essential features, contributing to the understanding of the transferability of learned patterns and the key characteristics distinguishing malicious and benign traffic, as highlighted in Chapter~\ref{chap:relevant-work}, Section~\ref{sec:ExplainableAITechniques}.

\subsection{Testing and Evaluation}\label{subsec:testing-evaluation}

A comprehensive testing and evaluation strategy is employed to ensure the robustness and reliability of the results. We assessed the performance of the classifiers using various metrics, including accuracy, precision, recall, and F1 score, as discussed in Chapter~\ref{chap:specification-design}, Section~\ref{subsec:EvaluationMetrics}. We calculated these metrics for each classifier on their respective test sets and when evaluated on the other dataset for transferability analysis, addressing RQ1 and RQ3, as discussed in Chapter~\ref{chap:specification-design}, Section~\ref{sec:TransferabilityEvaluation}.

\subsection{Novelty and Originality}\label{subsec:novelty-originality}

The novelty and originality of this research lie in the combination of the chosen datasets (CTU13 and CICIDS2017), classifiers (Random Forest and SVM), and the use of SHAP for explainability. This dissertation provides a unique perspective on network intrusion detection by investigating the transferability and generalisation of machine learning models across different datasets, as discussed in Chapter~\ref{chap:relevant-work}, Section~\ref{sec:PositioningSummary}.

The application of SHAP to interpret the predictions of the trained classifiers and identify the most relevant features for detecting specific types of attacks across datasets is a novel approach. This aspect of the research contributes to a deeper understanding of the transferability of learned patterns and the key characteristics distinguishing malicious and benign traffic, as highlighted in Chapter~\ref{chap:relevant-work}, Section~\ref{sec:ExplainableAITechniques}.

\subsection{Strengths and Limitations}\label{subsec:strengths-limitations}

The chosen methodology has several strengths. Random Forest and SVM classifiers are well-suited for handling the imbalanced and high-dimensional nature of the CTU13 and CICIDS2017 datasets. These classifiers have demonstrated their effectiveness in network intrusion detection tasks~\cite{farnaaz2016random, teng2017svm}, as discussed in Chapter~\ref{chap:relevant-work}, Sections~\ref{sec:RandomForestIntrusion} and~\ref{sec:SVMIntrusion}. Using CUML's GPU-accelerated models significantly reduces training times and improves scalability, enabling the efficient handling of large datasets, as discussed in Section~\ref{sec:ExperimentImplementation}.

However, there are also limitations to consider. The potential impact of dataset biases and the training data's representativeness on the models' transferability is a concern, as discussed in Chapter~\ref{chap:relevant-work}, Section~\ref{sec:ChallengesLimitations}. The computational complexity of the SHAP explanations may also pose challenges when dealing with large-scale datasets, even with GPU acceleration, as highlighted in Chapter~\ref{chap:conclusion-future-work}.

\section{Package Implementation}

To support the experiments described above, a set of software packages was developed for data preprocessing, model training, and result visualisation. The following subsections detail each of these packages.

\subsection{relabelCTU13.py}

\textbf{Purpose}: This Python script (Algorithm~\ref{alg:relabelCTU13}) is tasked with preprocessing the CTU13 dataset, ensuring its compatibility with the analysis framework. It specifically focuses on feature normalisation, class relabeling, and reordering of features to align with the structure of the CICIDS2017 dataset.

\textbf{Functionality}:

\begin{itemize}
    \item \textit{Feature Renaming}: Aligns the CTU13 dataset's feature names with those of CICIDS2017, facilitating direct comparison and joint analysis.
    \item \textit{Traffic Class Relabeling}: Converts traffic classification labels to a unified schema shared with CICIDS2017, enabling consistent interpretation of traffic types across datasets.
    \item \textit{Feature Reordering}: Adjusts the order of features in the CTU13 dataset to match that of CICIDS2017, ensuring that subsequent analysis scripts operate correctly without needing dataset-specific adjustments.
\end{itemize}

\subsection{relabelCICIDS2017.py}

\textbf{Purpose}: Similar to \texttt{relabelCTU13.py}, this script (Algorithm~\ref{alg:relabelCICIDS2017}) prepares the CICIDS2017 dataset for analysis by renaming features, relabeling traffic classes, and reordering features. The adjustments ensure that the CICIDS2017 dataset's structure is compatible with CTU13, facilitating combined analyses.

\textbf{Functionality}:

\begin{itemize}
    \item \textit{Mapping Feature Names}: Transforms the feature names in CICIDS2017 to align with CTU13's nomenclature, ensuring consistency in feature interpretation.
    \item \textit{Traffic Class Relabeling and Identification}: Updates the traffic class labels for compatibility and identifies common features between the datasets to focus on comparable data points.
    \item \textit{Feature Reordering}: Modifies the feature order in CICIDS2017 to conform to CTU13's layout, simplifying cross-dataset analyses.
\end{itemize}

\subsection{trainDummyClassifier.ipynb}

\textbf{Purpose}: A Jupyter Notebook (Algorithm~\ref{alg:trainDummyClassifier}) dedicated to training baseline Dummy Classifiers on the CTU13 and CICIDS2017 datasets. It sets a foundational performance benchmark for comparing more sophisticated Random Forest and SVM classifiers.

\textbf{Functionality}:

\begin{itemize}
    \item \textit{Training Process}: Outlines the steps for training Dummy Classifiers, including data loading, preprocessing application, and classifier training.
    \item \textit{Performance Evaluation}: Details the evaluation metrics used to assess the classifiers, providing a baseline for the effectiveness of subsequent, more complex models.
\end{itemize}

\subsection{trainRandomForest.ipynb}

\textbf{Purpose}: Trains and evaluates Random Forest classifiers (Algorithm~\ref{alg:trainRandomForest}) on both datasets using GPU-accelerated implementations. It explores the classifiers' transferability and employs the SHAP library for result interpretation.

\textbf{Functionality}:

\begin{itemize}
    \item \textit{GPU-Accelerated Training}: Leverages CUML's GPU-accelerated Random Forest implementation for efficient model training and evaluation.
    \item \textit{Transferability Testing}: Assesses the model's performance on both the training and alternative datasets to examine transferability.
    \item \textit{Feature Importance Analysis}: Utilises SHAP values to interpret the model's predictions and identify significant features, enhancing model transparency and understanding.
\end{itemize}

\subsection{trainSVM.ipynb}

\textbf{Purpose}: Similar to the Random Forest notebook, this Jupyter Notebook trains SVM classifiers (Algorithm~\ref{alg:trainSVM}) on the datasets, tests their transferability, and applies SHAP for interpretability.

\textbf{Functionality}:

\begin{itemize}
    \item \textit{GPU-Accelerated SVM Training}: Implements CUML's SVM for rapid model training, facilitating the handling of large datasets.
    \item \textit{Cross-Dataset Performance Evaluation}: Evaluates SVM classifiers' performance across different datasets to test model generalisability.
    \item \textit{SHAP-Based Explanation}: Applies SHAP to elucidate SVM classifiers' decision-making, spotlighting critical features that influence predictions.
\end{itemize}

\subsection{plotData.ipynb}

\textbf{Purpose}: This script (Algorithm~\ref{alg:plotData}) provides visualisations of dataset characteristics and model performance metrics, supporting the analysis and discussion of the experimental results presented in Chapter~\ref{chap:evaluation}.

\textbf{Functionality}:

\begin{itemize}
    \item \textit{Dataset Visualisation}: Generates descriptive statistics and visualisations of the CTU13 and CICIDS2017 datasets, providing insights into class distributions, feature distributions, and other relevant characteristics.
    \item \textit{Performance Metric Visualisation}: Creates visualisations of the performance metrics obtained from the experiments, including accuracy, precision, recall, and F1 score, facilitating the comparison of different classifiers and their transferability across datasets.
    \item \textit{SHAP Value Visualisation}: Visualises the SHAP values obtained from the explainable AI analysis, highlighting the most important features contributing to the classifiers' predictions and their transferability across datasets.
\end{itemize}

The implementation of these software packages and the experimental setup and evaluation strategies align with the research objectives and methodology outlined in Chapter~\ref{chap:specification-design}. The preprocessing scripts ensure the consistency and compatibility of the datasets, while the training modules and evaluation strategies address the research questions related to model transferability, dataset biases, and the insights provided by explainable AI techniques.

The use of GPU-accelerated implementations and the SHAP library for explainability reflects the state-of-the-art machine learning and cybersecurity research practices, as discussed in Chapter~\ref{chap:relevant-work}. The visualisations generated by the \texttt{plotData.ipynb} script support the analysis and interpretation of the experimental results, contributing to understanding the transferability of learned patterns and the key characteristics distinguishing malicious and benign traffic across different datasets.