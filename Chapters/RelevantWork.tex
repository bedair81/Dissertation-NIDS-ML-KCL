\chapter{Relevant Work}\label{chap:relevant-work}

This chapter comprehensively reviews related work in machine learning-based network intrusion detection. It covers state-of-the-art approaches for botnet detection using the CTU13 dataset, intrusion detection using the CICIDS2017 dataset, and the application of Random Forest and Support Vector Machines for intrusion detection tasks. Furthermore, it explores the use of explainable AI techniques, such as SHAP, to provide insights into the decision-making process of machine learning models in the context of intrusion detection. The chapter also discusses the challenges and limitations associated with using synthetic datasets and the importance of considering dataset biases and the dynamic nature of network traffic when developing and evaluating intrusion detection systems.

\section{Botnet Detection using CTU13 Dataset}

Several studies have utilised the CTU13 dataset for developing and evaluating botnet detection systems. Chowdhury et al.~\cite{chowdhury2017botnet} proposed a graph-based approach for botnet detection using the CTU13 dataset. They constructed a graph representation of the communication patterns among botnet-infected hosts and applied graph analysis techniques to identify botnets. The authors extracted features such as in-degree, out-degree, and betweenness centrality from the graph and used them to train a Random Forest classifier. Their approach achieved high accuracy in detecting botnets and demonstrated the potential of leveraging graph-based features for botnet detection.

In contrast to Chowdhury et al.’s work, this dissertation investigates the transferability of models trained on the CICIDS2017 dataset to detect botnet attacks in the CTU13 dataset. By exploring the generalisation capabilities of machine learning classifiers across different datasets, this work aims to assess the adaptability of learned patterns and features to new network environments. This aspect distinguishes the current research from previous studies that focused on developing botnet detection systems tailored to the CTU13 dataset.

Pektaş and Acarman~\cite{pektacs2019deep} applied deep learning techniques to the CTU13 dataset for botnet detection. They used a convolutional neural network (CNN) to learn discriminative features from raw network traffic data. The authors converted the traffic data of the CTU13 dataset into grayscale images through preprocessing and then fed them as input to the CNN.\@ The proposed model achieved high detection accuracy and showcased the effectiveness of deep learning in capturing complex patterns and behaviours associated with botnets.

While deep learning approaches have shown promising results, this dissertation explores the potential of traditional machine learning classifiers, such as Random Forest and Support Vector Machines, in detecting botnet attacks and investigates their transferability across datasets. By focusing on these well-established classifiers, this work aims to provide insights into the robustness and adaptability of these algorithms in botnet detection, complementing the findings of studies that have employed deep learning techniques.

\section{Intrusion Detection using CICIDS2017 Dataset}

Researchers have widely used the CICIDS2017 dataset to evaluate intrusion detection systems. Ustebay et al.~\cite{ustebay2018intrusion} proposed an intrusion detection system based on a multi-layer perceptron (MLP) classifier using the CICIDS2017 dataset. They performed extensive preprocessing on the dataset, including handling missing values, encoding categorical features, and scaling numerical features. The authors also applied recursive feature elimination with random forest to select the most relevant features for intrusion detection. Their MLP-based approach demonstrated the potential of neural network-based models for network intrusion detection.

In this dissertation, we leverage the CICIDS2017 dataset to train machine learning classifiers and investigate their transferability to detect botnet attacks in the CTU13 dataset. By focusing on the generalisation capabilities of the learned patterns and features, this work extends the findings of previous studies that have utilised the CICIDS2017 dataset for intrusion detection. The novelty lies in assessing the adaptability of models trained on one dataset to detect specific attacks in another dataset, providing insights into the transferability of learned representations across different network environments.

Aksu and Aydin~\cite{aksu2018detecting} conducted a comparative study of different machine learning algorithms for network intrusion detection using the CICIDS2017 dataset. They evaluated the performance of decision trees, random forests, and support vector machines. The authors preprocessed the dataset by removing redundant records, handling missing values, and applying normalisation techniques. They also performed feature selection using information gain and correlation-based methods. The experimental results showed that random forests outperformed other algorithms, highlighting the effectiveness of ensemble learning methods for intrusion detection.

This dissertation takes inspiration from Aksu and Aydin’s findings and employs Random Forest as one of the classifiers to investigate its transferability across datasets. By exploring the performance of Random Forest in detecting botnet attacks in the CTU13 dataset when trained on the CICIDS2017 dataset, this work contributes to understanding the robustness and adaptability of ensemble learning methods in the context of cross-dataset transferability.

\section{Random Forest for Intrusion Detection}\label{sec:RandomForestIntrusion}

Random Forest has been widely used for intrusion detection tasks. Farnaaz and Jabbar~\cite{farnaaz2016random} presented a model based on Random Forest and evaluated its performance on the NSL-KDD dataset. They performed feature selection using the Chi-square test to identify the most relevant features for intrusion detection and then trained the Random Forest classifier using the selected features. The proposed model demonstrated Random Forest’s effectiveness in detecting various types of network attacks.

While Farnaaz and Jabbar’s work focused on a single dataset, this dissertation explores the transferability of Random Forest classifiers trained on the CICIDS2017 dataset to detect botnet attacks in the CTU13 dataset. By investigating the generalisation capabilities of the learned patterns across different network environments, this work extends the findings of previous studies. It provides insights into the adaptability of Random Forest classifiers in the context of cross-dataset transferability.

Belouch et al.~\cite{belouch2018performance} applied Random Forest to the CICIDS2017 dataset for network intrusion detection. They compared the performance of Random Forest with other machine learning algorithms, including Decision Tree, Naive Bayes, and k-Nearest Neighbors. The authors preprocessed the dataset by removing redundant records and handling missing values. They also analysed the importance of different features in the dataset using the Random Forest feature importance measure. The experimental results showed that Random Forest outperformed other algorithms, further validating its effectiveness for intrusion detection.

This dissertation builds upon Belouch et al.’s findings by employing Random Forest as one of the classifiers and investigates its transferability to detect botnet attacks in a different dataset. By exploring the robustness and adaptability of the learned patterns across datasets, this work contributes to understanding the generalisation capabilities of Random Forest classifiers in the context of network intrusion detection.

\section{Support Vector Machines for Intrusion Detection}\label{sec:SVMIntrusion}

Support Vector Machines (SVM) have been extensively utilised for intrusion detection tasks. Kabir et al.~\cite{kabir2017network} proposed an SVM-based intrusion detection system and evaluated its performance on the NSL-KDD dataset. They used a genetic algorithm for feature selection to identify the most discriminative features for intrusion detection. The authors also optimised the SVM parameters using grid search to improve the model’s performance. The proposed system showcased SVM’s effectiveness in detecting various types of network attacks.

In contrast to Kabir et al.’s work, this dissertation focuses on the transferability of SVM classifiers trained on the CICIDS2017 dataset to detect botnet attacks in the CTU13 dataset. By exploring the generalisation capabilities of the learned patterns across different datasets, this work extends the findings of previous studies. It provides insights into the adaptability of SVM classifiers in the context of cross-dataset transferability.

Teng et al.~\cite{teng2017svm} applied SVM with different kernel functions for intrusion detection on the CICIDS2017 dataset. They compared the performance of linear, polynomial, and radial basis function (RBF) kernels. The authors preprocessed the dataset by removing redundant records and scaling the features. They also applied principal component analysis (PCA) for dimensionality reduction. The experimental results highlighted the importance of selecting appropriate kernel functions and tuning the SVM parameters for optimal performance.

This dissertation takes inspiration from Teng et al.’s findings and employs SVM as one of the classifiers to investigate its transferability in detecting botnet attacks across different datasets. By exploring the robustness and adaptability of the learned patterns, this work contributes to understanding the generalisation capabilities of SVM classifiers in the context of network intrusion detection.

\section{Explainable AI Techniques for Intrusion Detection}\label{sec:ExplainableAITechniques}

Explainable AI techniques have gained attention in intrusion detection to provide insights into the decision-making process of machine learning models. Warnecke et al.~\cite{warnecke2020evaluating} evaluated various explanation methods for deep learning-based intrusion detection systems, including SHAP.\@ They applied SHAP to a convolutional neural network (CNN) trained on the NSL-KDD dataset and analysed the importance of different features in the model’s predictions. The authors demonstrated that SHAP can provide meaningful insights into the decision-making process of deep learning models and help identify the most influential features for detecting specific attack types.

This dissertation takes inspiration from Warnecke et al.’s approach and employs SHAP to interpret the predictions of Random Forest and SVM classifiers trained on the CICIDS2017 dataset. By leveraging SHAP to provide insights into the transferability of learned patterns and the most relevant features for detecting botnet attacks in the CTU13 dataset, this work extends the application of explainable AI techniques to the context of cross-dataset transferability. The novelty lies in using SHAP to understand the key characteristics that distinguish malicious and benign traffic across different datasets, contributing to the interpretability and transparency of intrusion detection models.

Amarasinghe et al.~\cite{amarasinghe2018toward} employed SHAP to interpret the predictions of a deep learning-based network intrusion detection system. They trained a deep neural network on the NSL-KDD dataset and applied SHAP to explain the model’s predictions. The authors analysed the SHAP values to understand the impact of different features on the model’s decisions and identified the most discriminative features for detecting specific types of attacks. Their study highlights the potential of SHAP in providing interpretable explanations for deep learning-based intrusion detection systems.

In this dissertation, we leverage SHAP to interpret the predictions of traditional machine learning classifiers, such as Random Forest and SVM, and investigate the transferability of the learned patterns and the most relevant features for detecting botnet attacks across different datasets. By applying SHAP to these classifiers, this work extends the findings of previous studies. It provides insights into the interpretability and transferability of learned representations in the context of network intrusion detection.

Mane and Rao~\cite{mane2021explaining} used SHAP to explain the predictions of a random forest classifier for network intrusion detection. They trained the classifier on the NSL-KDD dataset and applied SHAP to interpret the model’s predictions. The authors visualised the SHAP values to understand the contribution of each feature towards the model’s output and identified the most critical features for detecting various types of network attacks. Their study demonstrates the effectiveness of SHAP in providing interpretable explanations for ensemble learning methods like random forests.

This dissertation builds upon Mane and Rao’s findings by employing SHAP to interpret the predictions of Random Forest and SVM classifiers trained on the CICIDS2017 dataset. By investigating the transferability of the learned patterns and the most relevant features for detecting botnet attacks in the CTU13 dataset, this work extends the application of SHAP to the context of cross-dataset transferability. The novelty lies in using SHAP to understand the key characteristics that contribute to detecting specific types of attacks across different network environments, enhancing the interpretability and generalizability of intrusion detection models.

\section{Challenges and Limitations}

While intrusion detection system developers and evaluators have frequently employed the CTU13 and CICIDS2017 datasets, it is necessary to recognise their limitations. Sommer and Paxson~\cite{sommer2010outside} have addressed the challenges of utilising synthetic datasets for network intrusion detection. These datasets may only partially capture the intricacy and variety of network traffic and require additional contextual information. Furthermore, the authors stress the necessity of more authentic and comprehensive datasets that consider the operational aspects and deployment hurdles of intrusion detection systems.

This dissertation acknowledges the limitations of synthetic datasets and emphasises the importance of considering dataset biases and the representativeness of training data when developing and evaluating intrusion detection systems. By investigating the transferability of machine learning models across different datasets, this work aims to address the challenges posed by dataset limitations and provide insights into the generalisation capabilities of intrusion detection models in real-world scenarios.

Moreover, Sommer and Paxson~\cite{sommer2010outside} highlight the importance of using representative and unbiased datasets for training machine learning models in network intrusion detection. They discuss the challenges posed by the dynamic nature of network traffic and the constant evolution of attack patterns, which can impact the long-term performance of the trained models. Buczak and Guven~\cite{buczak2015survey} provide a comprehensive survey of machine learning and data mining methods for cyber security intrusion detection. They discuss the considerations and challenges in applying machine learning techniques to network intrusion detection, including selecting appropriate algorithms, feature engineering, and model evaluation.

This dissertation considers the challenges associated with the dynamic nature of network traffic and the evolution of attack patterns. By investigating the transferability of machine learning models across different datasets and employing explainable AI techniques to gain insights into the decision-making process, this work aims to address these challenges and contribute to developing more robust and adaptable intrusion detection systems.

\section{Summary and Positioning}

This chapter has provided a comprehensive review of relevant work in machine learning-based network intrusion detection, focusing on botnet detection using the CTU13 dataset, intrusion detection using the CICIDS2017 dataset, and the application of Random Forests and Support Vector Machines for intrusion detection tasks. While previous studies have demonstrated the effectiveness of various machine learning algorithms in detecting network attacks, this dissertation explores a novel aspect by investigating machine learning models’ transferability and generalisation capabilities across different datasets.

This dissertation takes inspiration from existing approaches that have utilised Random Forest and Support Vector Machines for intrusion detection and applies these classifiers to the CICIDS2017 dataset. However, this work goes beyond previous studies by evaluating the performance of these classifiers in detecting botnet attacks in the CTU13 dataset, which represents a different network environment. By assessing the robustness and adaptability of the learned patterns and features across datasets, this dissertation aims to provide insights into the transferability of machine learning models in real-world scenarios, where a model trained on one dataset may be deployed to detect intrusions in a different network environment.

Furthermore, while the use of explainable AI techniques, such as SHAP, has been explored in previous studies for interpreting the predictions of intrusion detection models, this dissertation employs SHAP in a novel context. Specifically, it leverages SHAP to provide insights into the transferability of learned patterns and the most relevant features for detecting botnet attacks when applying classifiers trained on the CICIDS2017 dataset to the CTU13 dataset. By focusing on understanding the transferability of the learned patterns and the key characteristics that distinguish malicious and benign traffic across different datasets, this work contributes to the interpretability and transparency of intrusion detection models.

In summary, this dissertation builds upon existing research by investigating machine learning models’ transferability and generalisation capabilities for network intrusion detection, emphasising the importance of dataset representativeness and biases. By employing Random Forest and Support Vector Machines classifiers and leveraging explainable AI techniques in the context of cross-dataset transferability, this work aims to provide valuable insights into the robustness and adaptability of these algorithms in detecting botnet attacks across different datasets, contributing to the development of more effective and practical intrusion detection solutions.