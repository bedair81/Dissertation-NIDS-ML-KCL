\chapter{Introduction}

In recent years, the increasing prevalence and sophistication of cyber attacks have necessitated the development of robust network intrusion detection systems (NIDS). Traditional signature-based NIDS have struggled to keep pace with the evolving threat landscape, leading researchers to explore machine learning approaches for detecting novel and previously unseen attacks~\cite{marchetti2016analysis}. However, the effectiveness of machine learning-based NIDS is heavily dependent on the quality and representativeness of the datasets used for training and evaluation~\cite{engelen2021troubleshooting}.

This paper focuses on comparing two widely used datasets for network intrusion detection: CTU13~\cite{garcia2014empirical} and CICIDS2017~\cite{sharafaldin2018toward}. The CTU13 dataset contains real botnet traffic mixed with normal traffic and is often used for evaluating the performance of NIDS in detecting botnets. On the other hand, the CICIDS2017 dataset is a more recent and comprehensive dataset that includes a wide range of modern attacks such as DoS, DDoS, brute force, XSS, SQL injection, and infiltration~\cite{sharafaldin2018toward}.

The main objective of this research is to investigate the effectiveness of using a machine learning model trained on the CICIDS2017 dataset to detect botnet attacks in the CTU13 dataset. Specifically, we train a random forest classifier on the CICIDS2017 dataset and evaluate its performance on detecting botnet attacks in CTU13. This approach allows us to assess the generalizability and transferability of the learned features and patterns from one dataset to another.

However, it is important to note that machine learning-based NIDS are not without their challenges. Sommer and Paxon~\cite{sommer2010outside} highlighted the limitations of using machine learning for network intrusion detection, particularly in terms of the difficulty in obtaining representative training data and the potential for adversarial attacks. Pierazzi et al.~\cite{pierazzi2020intriguing} further explored the intriguing properties of adversarial attacks in the problem space of machine learning-based security systems.

We draw upon the recommendations of Arp et al.~\cite{arp2022and} on the dos and don'ts of machine learning for security to guide our experimental design and analysis. In addition to the random forest classifier, we also explore the use of explainable AI techniques~\cite{warnecke2020evaluating} to gain insights into the decision-making process of the trained model. This helps us understand the key features and patterns that contribute to the detection of botnet attacks and facilitates the interpretation of the model's predictions.