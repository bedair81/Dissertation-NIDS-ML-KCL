\chapter{Specification \& Design}\label{chap:specification-design}

\tikzstyle{dataset} = [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black, fill=blue!30]
\tikzstyle{process} = [rectangle, text centered, draw=black, fill=orange!30]
\tikzstyle{decision} = [rectangle, rounded corners, text centered, draw=black, fill=green!30]
\tikzstyle{arrow} = [thick,->,>=stealth]

This chapter outlines the experimental design of this dissertation, which focuses on three classifiers: the Dummy Classifier, the Random Forest Classifier, and the Support Vector Machine (SVM) Classifier. Informed by a thorough literature review, the experiments address the following research questions:

\begin{enumerate}
    \item[\textbf{RQ1}] How well do machine learning models trained on one dataset transfer and generalise to another in the context of network intrusion detection?
    \item[\textbf{RQ2}] What is the impact of dataset biases and representativeness on the performance of machine learning-based intrusion detection systems?
    \item[\textbf{RQ3}] How can explainable AI techniques, such as SHAP, provide insights into the transferability of learned patterns and the most relevant features for detecting specific attack types across datasets?
\end{enumerate}

The experiments utilise the CTU13 and CICIDS2017 datasets, selected for their distinct properties and attack types, making them ideal for assessing transferability (RQ1). CTU13 contains real botnet traffic~\cite{garcia2014empirical}, while CICIDS2017 offers a comprehensive range of modern attacks~\cite{sharafaldin2018toward}. Models are trained on CICIDS2017 and tested on CTU13 to evaluate cross-dataset performance. Detailed characteristics of these widely used datasets are provided in Chapter~\ref{chap:background}.

Pre-processing, implemented via Algorithms~\ref{alg:relabelCICIDS2017} and~\ref{alg:relabelCTU13}, standardises feature names and removes dataset-specific features to ensure consistency and mitigate biases (RQ2), aligning with best practices from Chapter~\ref{chap:relevant-work}. The classifiers are evaluated using accuracy, recall, precision, F1 score, and confusion matrices, offering a robust assessment of performance and transferability. SHAP (SHapley Additive exPlanations)~\cite{lundberg2017unified} is employed to interpret predictions and identify key features across datasets (RQ3), enhancing explainability as reviewed in Chapter~\ref{chap:relevant-work}, Section~\ref{sec:ExplainableAITechniques}.

A 60/40 training-testing split balances model training and evaluation, following recommendations by Buczak et al.~\cite{buczak2015survey}. Although neural networks were considered, Random Forest and SVM were chosen for their interpretability and effectiveness with imbalanced, high-dimensional data~\cite{farnaaz2016random, teng2017svm}.

\section{Experiments}\label{sec:Experiments}

The experiments involve training and testing the Dummy, Random Forest, and SVM Classifiers on both CICIDS2017 and CTU13 datasets. This setup assesses within-dataset performance and cross-dataset transferability (RQ1). The Dummy Classifier acts as a baseline, while Random Forest and SVM are selected for their ability to handle large, imbalanced datasets, as detailed in Chapter~\ref{chap:background}, Section~\ref{sec:classifiers}.

\subsection{Data Pre-processing}\label{subsec:DataPreprocessing}

Pre-processing ensures compatibility by standardising feature names and removing unique features (Algorithms~\ref{alg:relabelCICIDS2017} and~\ref{alg:relabelCTU13}). CICIDS2017 supports binary and multi-class tasks, while CTU13 is processed for binary classification (botnet vs. benign), aligning with the focus on botnet detection.

\subsection{Training and Testing Split}\label{subsec:TrainingTestingSplit}

A 60/40 split is applied to each dataset. Classifiers are trained on the CICIDS2017 training set and tested on both its testing set and the full CTU13 dataset to evaluate transferability (RQ1).

\subsection{Evaluation Metrics}\label{subsec:EvaluationMetrics}

Performance is assessed using:
\begin{itemize}
    \item \textbf{Accuracy}: Proportion of correct predictions.
    \item \textbf{Recall}: Ability to detect true positives.
    \item \textbf{Precision}: Accuracy of positive predictions.
    \item \textbf{F1 Score}: Harmonic mean of precision and recall.
    \item \textbf{Confusion Matrix}: Detailed classification breakdown.
\end{itemize}
These metrics, informed by Chapter~\ref{chap:relevant-work}, evaluate both within-dataset and cross-dataset performance.

\subsection{Explainable AI}\label{subsec:ExplainableAI}

SHAP interprets classifier predictions, identifying critical features for attack detection across datasets (RQ3). This builds on prior work in explainable AI for cybersecurity (Chapter~\ref{chap:relevant-work}, Section~\ref{sec:ExplainableAITechniques}).

\section{Classifier Configurations}\label{sec:ClassifierConfigurations}

\subsection{Dummy Classifier}\label{subsec:DummyClassifier}

The Dummy Classifier provides a baseline by randomly assigning labels based on class distribution (Figure~\ref{fig:DummyClassifierConfig}).

\begin{figure}[H]
    \centering
    \begin{tikzpicture}[node distance=1.5cm]
        \node (dataset) [dataset] {CICIDS2017 Dataset};
        \node (preproc) [process, below=of dataset] {Pre-processing};
        \node (dummy) [process, below=of preproc] {Dummy Classifier};
        \node (model) [process, below=of dummy] {Trained Classifier};
        \node (eval1) [decision, below left=0.2cm and -0.5cm of model] {Evaluation on CICIDS2017};
        \node (eval2) [decision, below right=0.2cm and -0.5cm of model] {Evaluation on CTU13};
        
        \draw [arrow] (dataset) -- (preproc);
        \draw [arrow] (preproc) -- node[anchor=east] {Training (60\%)} (dummy);
        \draw [arrow] (dummy) -- (model);
        \draw [arrow] (model) -| (eval1);
        \draw [arrow] (model) -| (eval2);
    \end{tikzpicture}
    \caption{Dummy Classifier Configuration}\label{fig:DummyClassifierConfig}
\end{figure}

\subsection{Random Forest and SVM Classifiers}\label{subsec:RandomForest_SVMClassifier}

Random Forest and SVM are trained on CICIDS2017 and tested on both datasets, with SHAP enhancing interpretability (Figure~\ref{fig:RandomForest_SVMClassifierConfig}).

\begin{figure}[H]
    \centering
    \begin{tikzpicture}[node distance=1.5cm]
        \node (dataset) [dataset] {CICIDS2017 Dataset};
        \node (preproc) [process, below=of dataset] {Pre-processing};
        \node (classifier) [process, below=of preproc] {Random Forest/SVM};
        \node (model) [process, below=of classifier] {Trained Classifier};
        \node (shap) [process, below=of model] {SHAP Interpretation};
        \node (eval1) [decision, below left=0.2cm and -0.5cm of shap] {Evaluation on CICIDS2017};
        \node (eval2) [decision, below right=0.2cm and -0.5cm of shap] {Evaluation on CTU13};
        
        \draw [arrow] (dataset) -- (preproc);
        \draw [arrow] (preproc) -- node[anchor=east] {Training (60\%)} (classifier);
        \draw [arrow] (classifier) -- (model);
        \draw [arrow] (model) -- (shap);
        \draw [arrow] (shap) -| (eval1);
        \draw [arrow] (shap) -| (eval2);
    \end{tikzpicture}
    \caption{Random Forest and SVM Classifier Configuration}\label{fig:RandomForest_SVMClassifierConfig}
\end{figure}

\section{Transferability Evaluation}\label{sec:TransferabilityEvaluation}

Transferability is evaluated by training classifiers on CICIDS2017 and testing on CTU13, using the metrics from Section~\ref{subsec:EvaluationMetrics}. High performance across both datasets indicates strong transferability, while a decline suggests limitations (RQ1). SHAP values reveal feature importance consistency, addressing dataset biases (RQ2) and explainability (RQ3), and reflecting real-world adaptability as noted in Chapter~\ref{chap:introduction}.

\section{Summary}\label{sec:Summary}

This chapter details the experimental design for assessing classifier transferability in network intrusion detection. The Dummy, Random Forest, and SVM Classifiers are trained on CICIDS2017 and tested on both CICIDS2017 and CTU13, with pre-processing ensuring compatibility. Performance metrics and SHAP insights address RQ1â€“RQ3, providing a foundation for the implementation in Chapter~\ref{chap:implementation}.