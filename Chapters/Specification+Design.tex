\chapter{Specification \& Design}

This chapter outlines the design and specification of the experiments conducted in this research, focusing on three main classifiers: Dummy Classifier, Random Forest Classifier, and Support Vector Machine Classifier. Based on the literature review, the paper designed the experimental setup to address the following key issues:

\begin{enumerate}
\item The need for assessing the transferability and generalisability of machine learning models across different datasets in the context of network intrusion detection~\cite{sommer2010outside, buczak2015survey}.
\item The importance of considering dataset biases and the representativeness of training data when developing and evaluating intrusion detection systems~\cite{sommer2010outside, engelen2021troubleshooting}.
\item The potential of explainable AI techniques, such as SHAP, to provide insights into the decision-making process of machine learning models and identify the most relevant features for detecting specific types of attacks~\cite{warnecke2020evaluating, amarasinghe2018toward, mane2021explaining}.
\end{enumerate}

The paper chose the CTU13 and CICIDS2017 datasets as they contain specific types of attacks and possess distinct properties that make them suitable for our research.CTU13 consists of real botnet traffic captured in a controlled environment~\cite{garcia2014empirical}, while CICIDS2017 is a more recent and comprehensive dataset designed for evaluating network intrusion detection systems, containing a wide range of modern attacks~\cite{sharafaldin2018toward}. By training models on CICIDS2017 and testing them on CTU13, this study aims to assess the transferability of learned patterns and features from a synthetic dataset to a real-world scenario, addressing the first identified issue.

To ensure uniformity and coherence across all datasets, we utilise the relabelCTU13.py and relabelCICIDS2017.py scripts during pre-processing. These scripts facilitate mapping dataset features to a standardised naming convention, promoting equitable comparisons and analysis. This approach effectively addresses the second concern surrounding dataset biases and representativeness.

The evaluation metrics used in this research, such as confusion matrix, accuracy, precision, recall, and F1 score, comprehensively assess the classifiers' performance in network intrusion detection. Furthermore, the SHAP library is employed to interpret the trained models' predictions and provide insights into their decision-making process. It addresses the third identified issue regarding the potential of explainable AI techniques in intrusion detection.

A common practice in machine learning is to split data into training and testing sets using a 60/40 ratio. This approach ensures a fair data distribution between the two sets, which helps prevent overfitting and promotes unbiased testing. This partitioning ratio has been widely accepted in the field as it balances training and assessing models, as noted in a research survey by Buczak et al.~\cite{buczak2015survey}.

Alternative designs and dataset selections were considered, such as using neural network-based classifiers (e.g., MLP and CNN) and other datasets. However, the focus on interpretability using SHAP and the comparative study by Belouch et al.~\cite{belouch2018performance} influenced the decision to use Random Forest and SVM classifiers. The combination of CICIDS2017 and CTU13 datasets aligns with the research objectives of assessing the effectiveness of machine learning classifiers in detecting botnet attacks and understanding the challenges and limitations of transferring learned patterns across datasets.

The following sections provide detailed descriptions of the experimental setup for each classifier, including the purpose, dataset-specific considerations, and evaluation processes. By addressing the identified issues, providing the rationale for the selected approaches, and deriving the experimental design from the synthesis of relevant literature, this chapter lays the foundation for a comprehensive and rigorous investigation into the transferability and explainability of machine learning models for network intrusion detection.

\section{Dummy Classifier}\label{sec:DummyClassifier}

\textbf{Purpose} The Dummy Classifier is a reference point for evaluating the efficacy of advanced classifiers like Random Forests and Support Vector Machines. If either of these classifiers fails to outperform the Dummy Classifier, it indicates that the model is not learning effectively from the data. The Dummy Classifier randomly assigns labels to the data, providing a baseline for comparison with more sophisticated models.

\subsection{CTU13}\label{subsec:DummyClassifierCTU13}

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
\node (dataset1) [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black] {CTU13 Dataset};
\node (preprocessing) [rectangle, draw, below=of dataset1] {Pre-processing(Binary)};
\node (dummyclassifier) [rectangle, draw, below=of preprocessing] {Dummy Classifier};
\node (trainedmodel) [rectangle, draw, below=of dummyclassifier] {Trained Model};
\node (evaluation) [rectangle, rounded corners, text centered, draw=black, below=of trainedmodel] {Evaluation};

\draw [->] (dataset1) -- (preprocessing);
\draw [->] (preprocessing) -- node[anchor=east] {Training Data (60\%)} (dummyclassifier);
\draw [->] (dummyclassifier) -- (trainedmodel);
\draw [->] (trainedmodel) -- (evaluation);
\draw [->] (preprocessing) -- node[anchor=south, xshift=1cm] {Testing Data (40\%)} ([xshift=1cm]preprocessing.east) |- ([xshift=1cm]trainedmodel.east) -- (trainedmodel);
\end{tikzpicture}
\caption{Dummy Classifier Flowchart for CTU13}\label{fig:DummyRandomFlowCTU13}
\end{figure}

The experiment commences by utilising the raw PCAP files from the CTU13 dataset, which exclusively includes botnet attacks and benign traffic. Firstly, a tool to extract flows, such as CICFlowMeter~\cite{lashkari2017characterization}, converts the raw PCAP files into CSV files that the classifiers can process. Prior to analysis, the data undergoes pre-processing to ensure compatibility with CICIDS2017. This pre-processing step incorporates the relabelCTU13.py script to relabel the dataset, ensuring consistency with the CICIDS2017 dataset. The relabeling process maps the CTU13 dataset's features to match the naming convention used in CICIDS2017, enabling fair comparisons between the two datasets. Given CTU13's exclusive focus on botnet attacks, there is no need for additional relabelling steps to unify attack names for the classifiers to group them.

After pre-processing, we divide the data into training and testing sets in a 60/40 proportion. The Dummy Classifier is trained on the training data (60\% of the dataset) and subsequently utilised to make predictions on the testing data (40\% of the dataset). The evaluation metrics include the confusion matrix, accuracy, precision, recall, and F1 score, comprehensively evaluating the classifier's effectiveness.

\subsection{Binary CICIDS2017}\label{subsec:DummyClassifierBinaryCICIDS2017}

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
\node (dataset1) [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black] {CICIDS2017 Dataset};
\node (preprocessing) [rectangle, draw, below=of dataset1] {Pre-processing (Binary)};
\node (dummyclassifier) [rectangle, draw, below=of preprocessing] {Dummy Classifier};
\node (trainedmodel) [rectangle, draw, below=of dummyclassifier] {Trained Model};
\node (evaluation) [rectangle, rounded corners, text centered, draw=black, below=of trainedmodel] {Evaluation};

\draw [->] (dataset1) -- (preprocessing);
\draw [->] (preprocessing) -- node[anchor=east] {Training Data (60\%)} (dummyclassifier);
\draw [->] (dummyclassifier) -- (trainedmodel);
\draw [->] (trainedmodel) -- (evaluation);
\draw [->] (preprocessing) -- node[anchor=south, xshift=1cm] {Testing Data (40\%)} ([xshift=1cm]preprocessing.east) |- ([xshift=1cm]trainedmodel.east) -- (trainedmodel);
\end{tikzpicture}
\caption{Dummy Classifier Flowchart for Binary CICIDS2017}\label{fig:DummyRandomFlowBinaryCICIDS2017}
\end{figure}

The experiment conducted using the CICIDS2017 dataset has a structure that closely resembles the CTU13 experiment. Firstly, a tool like CICFlowMeter~\cite{lashkari2017characterization} converts the raw PCAP files from CICIDS2017 into CSV files that the classifiers can process. The CSV files undergo pre-processing to ensure compatibility with the classifier and convert the dataset into a binary classification problem. The relabelCICIDS2017.py script provides a detailed explanation of the pre-processing step, which involves relabeling the dataset to maintain consistency with the CTU13 dataset. The script enables fair comparisons between the two datasets by mapping the CICIDS2017 dataset's features to match the naming convention used in the CTU13 dataset.

After pre-processing, we divide the data proportionally into training and testing sets at a 60/40 ratio. We use the training data, which accounts for 60\% of the dataset, to train the Dummy Classifier. Then, the classifier makes predictions on the testing data, representing 40\% of the dataset. The paper then uses the same performance metrics as the CTU13 experiment to evaluate the predictions.

\subsection{Multi-class CICIDS2017}\label{subsec:DummyClassifierMultiCICIDS2017}

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
\node (dataset1) [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black] {CICIDS2017 Dataset};
\node (preprocessing) [rectangle, draw, below=of dataset1] {Pre-processing (Multi-class)};
\node (dummyclassifier) [rectangle, draw, below=of preprocessing] {Dummy Classifier};
\node (trainedmodel) [rectangle, draw, below=of dummyclassifier] {Trained Model};
\node (evaluation) [rectangle, rounded corners, text centered, draw=black, below=of trainedmodel] {Evaluation};

\draw [->] (dataset1) -- (preprocessing);
\draw [->] (preprocessing) -- node[anchor=east] {Training Data (60\%)} (dummyclassifier);
\draw [->] (dummyclassifier) -- (trainedmodel);
\draw [->] (trainedmodel) -- (evaluation);
\draw [->] (preprocessing) -- node[anchor=south, xshift=1cm] {Testing Data (40\%)} ([xshift=1cm]preprocessing.east) |- ([xshift=1cm]trainedmodel.east) -- (trainedmodel);
\end{tikzpicture}
\caption{Dummy Classifier Flowchart for Multi-class CICIDS2017}\label{fig:DummyRandomFlowMultiCICIDS2017}
\end{figure}

Compared to the CTU13 dataset, the CICIDS2017 dataset boasts various attack types, making it an excellent choice for a multi-class classification strategy. The inclusion of the multi-class experiment aims to check if any different attack types in CICIDS2017 follow similar structures regarding their flows to botnet attacks from CTU13. If a classifier trained on CICIDS2017 can successfully discover botnet attacks in CTU13, it would suggest that some attack types in CICIDS2017 share similar flow characteristics with botnet attacks.

Firstly, a tool like CICFlowMeter~\cite{lashkari2017characterization} converts the raw PCAP files from CICIDS2017 into CSV files that the classifiers can process. The CSV files undergo pre-processing to ensure the classifier's compatibility and transform the dataset into a multi-class classification challenge. As described in the relabelCICIDS2017.py script, the pre-processing stage entails relabeling the dataset to maintain consistency with the CTU13 dataset, similar to the binary classification experiment.

After pre-processing, we divided the dataset into training and testing sets with a 60/40 ratio. We trained the Dummy Classifier on the training data, which accounted for 60\% of the dataset. Then, we applied the classifier to the testing data, representing 40\% of the dataset, to generate predictions. Finally, we used the same performance metrics from previous experiments to assess these predictions.

\section{Random Forest Classifier}\label{sec:RandomForestClassifier}

\subsection{CTU13}\label{subsec:RandomForestClassifierCTU13}
\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
\node (dataset1) [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black] {CTU13 Dataset};
\node (pre-processing) [rectangle, draw, below=of dataset1] {Pre-processing(Binary)};
\node (randomforest) [rectangle, draw, below=of preprocessing] {Random Forest Classifier};
\node (trainedmodel) [rectangle, draw, below=of randomforest] {Trained Model};
\node (shap) [rectangle, draw, below=of trainedmodel] {SHAP};
\node (evaluation) [rectangle, rounded corners, text centered, draw=black, below=of shap] {Evaluation};

\draw [->] (dataset1) -- (preprocessing);
\draw [->] (preprocessing) -- node[anchor=east] {Training Data (60\%)} (randomforest);
\draw [->] (randomforest) -- (trainedmodel);
\draw [->] (trainedmodel) -- (shap);
\draw [->] (shap) -- (evaluation);
\draw [->] (preprocessing) -- node[anchor=south, xshift=1cm] {Testing Data (40\%)} ([xshift=1cm]preprocessing.east) |- ([xshift=1cm]trainedmodel.east) -- (trainedmodel);
\end{tikzpicture}
\caption{Random Forest Classifier Flowchart for CTU13}\label{fig:RandomForestFlowCTU13}
\end{figure}

The experiment on the CTU13 dataset utilising the Random Forest Classifier follows a similar process to the previous Dummy Classifier experiment. Firstly, a tool like CICFlowMeter~\cite{lashkari2017characterization} converts the raw PCAP files from CTU13 into CSV files that the classifiers can process. To ensure consistency with the CICIDS2017 dataset, we utilise the relabelCTU13.py script for pre-processing the CSV files. Once pre-processing is complete, we split the data into training and testing sets with a 60/40 ratio. Next, the Random Forest Classifier is trained on the training data (60\% of the dataset) and utilised to predict the testing data (40\% of the dataset). Finally, the SHAP library for explanations and the same performance metrics used in the previous Dummy Classifier experiment are applied to evaluate the predictions.

\subsection{Binary CICIDS2017}\label{subsec:RandomForestBinaryCICIDS2017}
\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
\node (dataset1) [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black] {CICIDS2017 Dataset};
\node (preprocessing) [rectangle, draw, below=of dataset1] {Pre-processing (Binary)};
\node (randomforest) [rectangle, draw, below=of preprocessing] {Random Forest Classifier};
\node (trainedmodel) [rectangle, draw, below=of randomforest] {Trained Model};
\node (shap) [rectangle, draw, below=of trainedmodel] {SHAP};
\node (evaluation) [rectangle, rounded corners, text centered, draw=black, below=of shap] {Evaluation};

\draw [->] (dataset1) -- (preprocessing);
\draw [->] (preprocessing) -- node[anchor=east] {Training Data (60\%)} (randomforest);
\draw [->] (randomforest) -- (trainedmodel);
\draw [->] (trainedmodel) -- (shap);
\draw [->] (shap) -- (evaluation);
\draw [->] (preprocessing) -- node[anchor=south, xshift=1cm] {Testing Data (40\%)} ([xshift=1cm]preprocessing.east) |- ([xshift=1cm]trainedmodel.east) -- (trainedmodel);
\end{tikzpicture}
\caption{Random Forest Classifier Flowchart for Binary CICIDS2017}\label{fig:RandomForestFlowBinaryCICIDS2017}
\end{figure}

To execute the Random Forest Classifier experiment on the binary CICIDS2017 dataset, we first use a tool like CICFlowMeter~\cite{lashkari2017characterization} to convert the raw PCAP files from CICIDS2017 into CSV files that the classifiers can process. We then pre-process the CSV files using the relabelCICIDS2017.py script. We did this to ensure consistency with the CTU13 dataset and to convert the problem into a binary classification task. After that, we divided the pre-processed data into training and testing sets using a 60/40 ratio. We trained the Random Forest Classifier on the training data, which accounted for 60\% of the dataset. We used it to make predictions on the testing data, which accounted for 40\% of the dataset. Finally, we evaluated our predictions using the SHAP library for explanations and the same set of performance metrics as in the prior experiments.

\subsection{Multi-class CICIDS2017}\label{subsec:RandomForestMultiCICIDS2017}
\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
\node (dataset1) [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black] {CICIDS2017 Dataset};
\node (preprocessing) [rectangle, draw, below=of dataset1] {Pre-processing (Multi-class)};
\node (randomforest) [rectangle, draw, below=of preprocessing] {Random Forest Classifier};
\node (trainedmodel) [rectangle, draw, below=of randomforest] {Trained Model};
\node (shap) [rectangle, draw, below=of trainedmodel] {SHAP};
\node (evaluation) [rectangle, rounded corners, text centered, draw=black, below=of shap] {Evaluation};

\draw [->] (dataset1) -- (preprocessing);
\draw [->] (preprocessing) -- node[anchor=east] {Training Data (60\%)} (randomforest);
\draw [->] (randomforest) -- (trainedmodel);
\draw [->] (trainedmodel) -- (shap);
\draw [->] (shap) -- (evaluation);
\draw [->] (preprocessing) -- node[anchor=south, xshift=1cm] {Testing Data (40\%)} ([xshift=1cm]preprocessing.east) |- ([xshift=1cm]trainedmodel.east) -- (trainedmodel);
\end{tikzpicture}
\caption{Random Forest Classifier Flowchart for Multi-class CICIDS2017}\label{fig:RandomForestFlowMultiCICIDS2017}
\end{figure}

For the multi-class CICIDS2017 dataset Random Forest Classifier experiment, the goal is to investigate if the Random Forest Classifier can learn patterns from various attack types in CICIDS2017 that are similar to botnet attacks in CTU13. If the classifier can successfully detect botnet attacks in CTU13 after being trained on CICIDS2017, it would suggest that some attack types in CICIDS2017 share similar flow characteristics with botnet attacks.

We first use a tool like CICFlowMeter~\cite{lashkari2017characterization} to convert the raw PCAP files from CICIDS2017 into CSV files that the classifiers can process. We then pre-process the CSV files using the relabelCICIDS2017.py script to ensure consistency with the CTU13 dataset and convert the problem to a multi-class classification task. Then, we split the pre-processed data into training and testing sets using a 60/40 ratio. We use the training data (60\% of the dataset) to train the Random Forest Classifier, which subsequently predicts the testing data (40\% of the dataset). Finally, we evaluate the predictions using the SHAP library for explanations and the same set of performance metrics as in the previous experiments.

\section{Support Vector Machine Classifier}\label{sec:SVMClassifier}

\subsection{CTU13}\label{subsec:SVMClassifierCTU13}
\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
\node (dataset1) [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black] {CTU13 Dataset};
\node (pre-processing) [rectangle, draw, below=of dataset1] {Pre-processing(Binary)};
\node (SVM) [rectangle, draw, below=of pre-processing] {SVM Classifier};
\node (trainedmodel) [rectangle, draw, below=of SVM] {Trained Model};
\node (shap) [rectangle, draw, below=of trainedmodel] {SHAP};
\node (evaluation) [rectangle, rounded corners, text centered, draw=black, below=of shap] {Evaluation};

\draw [->] (dataset1) -- (preprocessing);
\draw [->] (preprocessing) -- node[anchor=east] {Training Data (60\%)} (SVM);
\draw [->] (SVM) -- (trainedmodel);
\draw [->] (trainedmodel) -- (shap);
\draw [->] (shap) -- (evaluation);
\draw [->] (preprocessing) -- node[anchor=south, xshift=1cm] {Testing Data (40\%)} ([xshift=1cm]preprocessing.east) |- ([xshift=1cm]trainedmodel.east) -- (trainedmodel);
\end{tikzpicture}
\caption{SVM Classifier Flowchart for CTU13}\label{fig:SVMFlowCTU13}
\end{figure}

For the SVM Classifier experiment on the CTU13 dataset, we first use a tool like CICFlowMeter~\cite{lashkari2017characterization} to convert the raw PCAP files from CTU13 into CSV files that the classifiers can process. We then pre-process the CSV files using the relabelCTU13.py script to ensure consistency with the CICIDS2017 dataset. Then, we split the pre-processed data into training and testing sets at a 60/40 ratio. After that, we train the SVM Classifier using the training data comprising 60\% of the dataset. Once we complete the classifier training, we use it to predict the testing data that constitutes 40\% of the dataset. Finally, we evaluate the predictions using the SHAP library for explanations and the same set of performance metrics as in the previous experiments.

\subsection{Binary CICIDS2017}\label{subsec:SVMClassifierBinaryCICIDS2017}
\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
\node (dataset1) [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black] {CICIDS2017 Dataset};
\node (preprocessing) [rectangle, draw, below=of dataset1] {Pre-processing (Binary)};
\node (SVM) [rectangle, draw, below=of pre-processing] {SVM Classifier};
\node (trainedmodel) [rectangle, draw, below=of SVM] {Trained Model};
\node (shap) [rectangle, draw, below=of trainedmodel] {SHAP};
\node (evaluation) [rectangle, rounded corners, text centered, draw=black, below=of shap] {Evaluation};

\draw [->] (dataset1) -- (preprocessing);
\draw [->] (preprocessing) -- node[anchor=east] {Training Data (60\%)} (SVM);
\draw [->] (SVM) -- (trainedmodel);
\draw [->] (trainedmodel) -- (shap);
\draw [->] (shap) -- (evaluation);
\draw [->] (preprocessing) -- node[anchor=south, xshift=1cm] {Testing Data (40\%)} ([xshift=1cm]preprocessing.east) |- ([xshift=1cm]trainedmodel.east) -- (trainedmodel);
\end{tikzpicture}
\caption{SVM Classifier Flowchart for Binary CICIDS2017}\label{fig:SVMFlowBinaryCICIDS2017}
\end{figure}

To conduct the SVM Classifier experiment on the binary dataset CICIDS2017, we first use a tool like CICFlowMeter~\cite{lashkari2017characterization} to convert the raw PCAP files from CICIDS2017 into CSV files that the classifiers can process. We then pre-process the CSV files using the relabelCICIDS2017.py script. The relabeling ensures consistency with the CTU13 dataset and transforms the problem into a binary classification task. Once we complete the pre-processing, we split the data into training and testing sets with a 60/40 ratio. We use the training data, which accounts for 60\% of the dataset, to train the SVM Classifier. Afterwards, we utilise the trained model to make predictions on the testing data, which accounts for 40\% of the dataset. Finally, we evaluate the predictions using the SHAP library for explanations and the same set of performance metrics as in our previous experiments.

\subsection{Multi-class CICIDS2017}\label{subsec:SVMClassifierMultiCICIDS2017}
\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
\node (dataset1) [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black] {CICIDS2017 Dataset};
\node (preprocessing) [rectangle, draw, below=of dataset1] {Pre-processing (Multi-class)};
\node (SVM) [rectangle, draw, below=of pre-processing] {SVM Classifier};
\node (trainedmodel) [rectangle, draw, below=of SVM] {Trained Model};
\node (shap) [rectangle, draw, below=of trainedmodel] {SHAP};
\node (evaluation) [rectangle, rounded corners, text centered, draw=black, below=of shap] {Evaluation};

\draw [->] (dataset1) -- (preprocessing);
\draw [->] (preprocessing) -- node[anchor=east] {Training Data (60\%)} (SVM);
\draw [->] (SVM) -- (trainedmodel);
\draw [->] (trainedmodel) -- (shap);
\draw [->] (shap) -- (evaluation);
\draw [->] (preprocessing) -- node[anchor=south, xshift=1cm] {Testing Data (40\%)} ([xshift=1cm]preprocessing.east) |- ([xshift=1cm]trainedmodel.east) -- (trainedmodel);
\end{tikzpicture}
\caption{SVM Classifier Flowchart for Multi-class CICIDS2017}\label{fig:SVMFlowMultiCICIDS2017}
\end{figure}

The SVM Classifier experiment on the multi-class CICIDS2017 dataset aims to explore if the SVM Classifier can identify similarities between the flow structures of various attack types in CICIDS2017 and botnet attacks in CTU13. If the SVM Classifier, trained on CICIDS2017, can effectively detect botnet attacks in CTU13, it would indicate that certain attack types in CICIDS2017 exhibit similar flow characteristics to botnet attacks.

We first use a tool like CICFlowMeter~\cite{lashkari2017characterization} to convert the raw PCAP files from CICIDS2017 into CSV files that the classifiers can process. We then pre-process the CSV files using the relabelCICIDS2017.py script to ensure consistency with the CTU13 dataset and transform the problem into a multi-class classification task. After pre-processing, we divided the data into training and testing sets in a 60/40 ratio. We used the training data, which comprised 60\% of the dataset, to train the SVM Classifier. Next, we utilised the trained classifier to make predictions on the testing data, which accounted for 40\% of the dataset. Finally, we evaluated the predictions using the SHAP library for explanations and the same performance metrics used in the previous experiments.