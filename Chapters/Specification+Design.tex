\chapter{Specification \& Design}

This chapter outlines the design and specification of the experiments conducted in this research, focusing on three main classifiers: Dummy Classifier, Random Forest Classifier, and Support Vector Machine Classifier. Based on the literature review, the paper designed the experimental setup to address the following key issues:

\begin{enumerate}
\item The need for assessing the transferability and generalisability of machine learning models across different datasets in the context of network intrusion detection~\cite{sommer2010outside, buczak2015survey}.
\item The importance of considering dataset biases and the representativeness of training data when developing and evaluating intrusion detection systems~\cite{sommer2010outside, engelen2021troubleshooting}.
\item The potential of explainable AI techniques, such as SHAP, to provide insights into the decision-making process of machine learning models and identify the most relevant features for detecting specific types of attacks~\cite{warnecke2020evaluating, amarasinghe2018toward, mane2021explaining}.
\end{enumerate}

The paper chose the CTU13 and CICIDS2017 datasets as they contain specific types of attacks and possess distinct properties that make them suitable for our research.CTU13 consists of real botnet traffic captured in a controlled environment~\cite{garcia2014empirical}, while CICIDS2017 is a more recent and comprehensive dataset designed for evaluating network intrusion detection systems, containing a wide range of modern attacks~\cite{sharafaldin2018toward}. By training models on CICIDS2017 and testing them on CTU13, this study aims to assess the transferability of learned patterns and features from a synthetic dataset to a real-world scenario, addressing the first identified issue.

To ensure uniformity and coherence across all datasets, we utilise the relabelCTU13.py and relabelCICIDS2017.py scripts during pre-processing. These scripts facilitate mapping dataset features to a standardised naming convention, promoting equitable comparisons and analysis. This approach effectively addresses the second concern surrounding dataset biases and representativeness.

The evaluation metrics used in this research, such as confusion matrix, accuracy, precision, recall, and F1 score, comprehensively assess the classifiers' performance in network intrusion detection. Furthermore, the SHAP library is employed to interpret the trained models' predictions and provide insights into their decision-making process. It addresses the third identified issue regarding the potential of explainable AI techniques in intrusion detection.

A common practice in machine learning is to split data into training and testing sets using a 60/40 ratio. This approach ensures a fair data distribution between the two sets, which helps prevent overfitting and promotes unbiased testing. This partitioning ratio has been widely accepted in the field as it balances training and assessing models, as noted in a research survey by Buczak et al.~\cite{buczak2015survey}.

Alternative designs and dataset selections were considered, such as using neural network-based classifiers (e.g., MLP and CNN) and other datasets. However, the focus on interpretability using SHAP and the comparative study by Belouch et al.~\cite{belouch2018performance} influenced the decision to use Random Forest and SVM classifiers. The combination of CICIDS2017 and CTU13 datasets aligns with the research objectives of assessing the effectiveness of machine learning classifiers in detecting botnet attacks and understanding the challenges and limitations of transferring learned patterns across datasets.

The following sections provide detailed descriptions of the experimental setup for each classifier, including the purpose, dataset-specific considerations, and evaluation processes. By addressing the identified issues, providing the rationale for the selected approaches, and deriving the experimental design from the synthesis of relevant literature, this chapter lays the foundation for a comprehensive and rigorous investigation into the transferability and explainability of machine learning models for network intrusion detection.

\section{Dummy Classifier}\label{sec:DummyClassifier}

\textbf{Purpose} The Dummy Classifier is a reference point for evaluating the efficacy of advanced classifiers like Random Forests and Support Vector Machines. If either of these classifiers fails to outperform the Dummy Classifier, it indicates that the model is not learning effectively from the data. The Dummy Classifier randomly assigns labels to the data, providing a baseline for comparison with more sophisticated models.

\subsection{CTU13}\label{subsec:DummyClassifierCTU13}

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
\node (dataset1) [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black] {CTU13 Dataset};
\node (pre-processing) [rectangle, draw, below=of dataset1] {Pre-processing(Binary)};
\node (dummyclassifier) [rectangle, draw, below=of pre-processing] {Dummy Classifier};
\node (trainedmodel) [rectangle, draw, below=of dummyclassifier] {Trained Model};
\node (evaluation) [rectangle, rounded corners, text centered, draw=black, below=of trainedmodel] {Evaluation};

\draw [->] (dataset1) -- (pre-processing);
\draw [->] (pre-processing) -- node[anchor=east] {Training Data (60\%)} (dummyclassifier);
\draw [->] (dummyclassifier) -- (trainedmodel);
\draw [->] (trainedmodel) -- (evaluation);
\draw [->] (pre-processing) -- node[anchor=south, xshift=1cm] {Testing Data (40\%)} ([xshift=1cm]pre-processing.east) |- ([xshift=1cm]trainedmodel.east) -- (trainedmodel);
\end{tikzpicture}
\caption{Dummy Classifier Flowchart for CTU13}\label{fig:DummyRandomFlowCTU13}
\end{figure}

The experiment commences by utilising the raw PCAP files from the CTU13 dataset, which exclusively includes botnet attacks and benign traffic. Firstly, a tool to extract flows, such as CICFlowMeter~\cite{lashkari2017characterization}, converts the raw PCAP files into CSV files that the classifiers can process. Prior to analysis, the data undergoes pre-processing to ensure compatibility with CICIDS2017. This pre-processing step incorporates the relabelCTU13.py script to relabel the dataset, ensuring consistency with the CICIDS2017 dataset. The relabeling process maps the CTU13 dataset's features to match the naming convention used in CICIDS2017, enabling fair comparisons between the two datasets. Given CTU13's exclusive focus on botnet attacks, there is no need for additional relabelling steps to unify attack names for the classifiers to group them.

After pre-processing, we divide the data into training and testing sets in a 60/40 proportion. The Dummy Classifier is trained on the training data (60\% of the dataset) and subsequently utilised to make predictions on the testing data (40\% of the dataset). The evaluation metrics include the confusion matrix, accuracy, precision, recall, and F1 score, comprehensively evaluating the classifier's effectiveness.

\subsection{Binary CICIDS2017}\label{subsec:DummyClassifierBinaryCICIDS2017}

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
\node (dataset1) [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black] {CICIDS2017 Dataset};
\node (pre-processing) [rectangle, draw, below=of dataset1] {Pre-processing (Binary)};
\node (dummyclassifier) [rectangle, draw, below=of pre-processing] {Dummy Classifier};
\node (trainedmodel) [rectangle, draw, below=of dummyclassifier] {Trained Model};
\node (evaluation) [rectangle, rounded corners, text centered, draw=black, below=of trainedmodel] {Evaluation};

\draw [->] (dataset1) -- (pre-processing);
\draw [->] (pre-processing) -- node[anchor=east] {Training Data (60\%)} (dummyclassifier);
\draw [->] (dummyclassifier) -- (trainedmodel);
\draw [->] (trainedmodel) -- (evaluation);
\draw [->] (pre-processing) -- node[anchor=south, xshift=1cm] {Testing Data (40\%)} ([xshift=1cm]pre-processing.east) |- ([xshift=1cm]trainedmodel.east) -- (trainedmodel);
\end{tikzpicture}
\caption{Dummy Classifier Flowchart for Binary CICIDS2017}\label{fig:DummyRandomFlowBinaryCICIDS2017}
\end{figure}

The experiment conducted using the CICIDS2017 dataset has a structure that closely resembles the CTU13 experiment (\ref{subsec:DummyClassifierCTU13}), with some key differences. The pre-processing step involves relabeling the dataset to maintain consistency with the CTU13 dataset and converting the problem into a binary classification task, as detailed in the relabelCICIDS2017.py script. The training and testing data split, evaluation metrics, and overall process remain the same as in the CTU13 experiment.

\subsection{Multi-class CICIDS2017}\label{subsec:DummyClassifierMultiCICIDS2017}

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
\node (dataset1) [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black] {CICIDS2017 Dataset};
\node (pre-processing) [rectangle, draw, below=of dataset1] {Pre-processing (Multi-class)};
\node (dummyclassifier) [rectangle, draw, below=of pre-processing] {Dummy Classifier};
\node (trainedmodel) [rectangle, draw, below=of dummyclassifier] {Trained Model};
\node (evaluation) [rectangle, rounded corners, text centered, draw=black, below=of trainedmodel] {Evaluation};

\draw [->] (dataset1) -- (pre-processing);
\draw [->] (pre-processing) -- node[anchor=east] {Training Data (60\%)} (dummyclassifier);
\draw [->] (dummyclassifier) -- (trainedmodel);
\draw [->] (trainedmodel) -- (evaluation);
\draw [->] (pre-processing) -- node[anchor=south, xshift=1cm] {Testing Data (40\%)} ([xshift=1cm]pre-processing.east) |- ([xshift=1cm]trainedmodel.east) -- (trainedmodel);
\end{tikzpicture}
\caption{Dummy Classifier Flowchart for Multi-class CICIDS2017}\label{fig:DummyRandomFlowMultiCICIDS2017}
\end{figure}

The multi-class CICIDS2017 experiment follows a similar process to the binary CICIDS2017 experiment (\ref{subsec:DummyClassifierBinaryCICIDS2017}), with the main difference being the transformation of the dataset into a multi-class classification challenge during the pre-processing stage. The goal is to check if any different attack types in CICIDS2017 share similar flow structures with botnet attacks from CTU13. The training and testing data split, evaluation metrics, and overall process remain the same as in the previous experiments.

\section{Random Forest Classifier}\label{sec:RandomForestClassifier}

\textbf{Purpose} The Random Forest Classifier is an ensemble learning method that combines multiple decision trees to make predictions~\cite{hastie2009random}. It has advantages such as handling high-dimensional data, robustness to noise and outliers, and capturing complex feature interactions. Random Forest has shown promising results in intrusion detection tasks~\cite{farnaaz2016random, belouch2018performance}.

\subsection{CTU13}\label{subsec:RandomForestClassifierCTU13}
\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
\node (dataset1) [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black] {CTU13 Dataset};
\node (pre-processing) [rectangle, draw, below=of dataset1] {Pre-processing(Binary)};
\node (randomforest) [rectangle, draw, below=of pre-processing] {Random Forest Classifier};
\node (trainedmodel) [rectangle, draw, below=of randomforest] {Trained Model};
\node (shap) [rectangle, draw, below=of trainedmodel] {SHAP};
\node (evaluation) [rectangle, rounded corners, text centered, draw=black, below=of shap] {Evaluation};

\draw [->] (dataset1) -- (pre-processing);
\draw [->] (pre-processing) -- node[anchor=east] {Training Data (60\%)} (randomforest);
\draw [->] (randomforest) -- (trainedmodel);
\draw [->] (trainedmodel) -- (shap);
\draw [->] (shap) -- (evaluation);
\draw [->] (pre-processing) -- node[anchor=south, xshift=1cm] {Testing Data (40\%)} ([xshift=1cm]pre-processing.east) |- ([xshift=1cm]trainedmodel.east) -- (trainedmodel);
\end{tikzpicture}
\caption{Random Forest Classifier Flowchart for CTU13}\label{fig:RandomForestFlowCTU13}
\end{figure}

The Random Forest Classifier experiment on the CTU13 dataset follows a similar process to the Dummy Classifier experiment (\ref{subsec:DummyClassifierCTU13}), with the fundamental difference being the use of the Random Forest algorithm for classification. The pre-processing steps, training and testing data split, and evaluation metrics remain the same. We also use the SHAP library to explain the classifier's predictions.

\subsection{Binary CICIDS2017}\label{subsec:RandomForestBinaryCICIDS2017}
\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
\node (dataset1) [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black] {CICIDS2017 Dataset};
\node (pre-processing) [rectangle, draw, below=of dataset1] {Pre-processing (Binary)};
\node (randomforest) [rectangle, draw, below=of pre-processing] {Random Forest Classifier};
\node (trainedmodel) [rectangle, draw, below=of randomforest] {Trained Model};
\node (shap) [rectangle, draw, below=of trainedmodel] {SHAP};
\node (evaluation) [rectangle, rounded corners, text centered, draw=black, below=of shap] {Evaluation};

\draw [->] (dataset1) -- (pre-processing);
\draw [->] (pre-processing) -- node[anchor=east] {Training Data (60\%)} (randomforest);
\draw [->] (randomforest) -- (trainedmodel);
\draw [->] (trainedmodel) -- (shap);
\draw [->] (shap) -- (evaluation);
\draw [->] (pre-processing) -- node[anchor=south, xshift=1cm] {Testing Data (40\%)} ([xshift=1cm]pre-processing.east) |- ([xshift=1cm]trainedmodel.east) -- (trainedmodel);
\end{tikzpicture}
\caption{Random Forest Classifier Flowchart for Binary CICIDS2017}\label{fig:RandomForestFlowBinaryCICIDS2017}
\end{figure}

The Random Forest Classifier experiment on the binary CICIDS2017 dataset is similar to the Dummy Classifier experiment on the binary CICIDS2017 dataset (\ref{subsec:DummyClassifierBinaryCICIDS2017}), with the main difference being the use of the Random Forest algorithm for classification. The pre-processing steps, training and testing data split, and evaluation metrics remain the same. We also use the SHAP library to explain the classifier's predictions.

\subsection{Multi-class CICIDS2017}\label{subsec:RandomForestMultiCICIDS2017}
\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
\node (dataset1) [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black] {CICIDS2017 Dataset};
\node (pre-processing) [rectangle, draw, below=of dataset1] {Pre-processing (Multi-class)};
\node (randomforest) [rectangle, draw, below=of pre-processing] {Random Forest Classifier};
\node (trainedmodel) [rectangle, draw, below=of randomforest] {Trained Model};
\node (shap) [rectangle, draw, below=of trainedmodel] {SHAP};
\node (evaluation) [rectangle, rounded corners, text centered, draw=black, below=of shap] {Evaluation};

\draw [->] (dataset1) -- (pre-processing);
\draw [->] (pre-processing) -- node[anchor=east] {Training Data (60\%)} (randomforest);
\draw [->] (randomforest) -- (trainedmodel);
\draw [->] (trainedmodel) -- (shap);
\draw [->] (shap) -- (evaluation);
\draw [->] (pre-processing) -- node[anchor=south, xshift=1cm] {Testing Data (40\%)} ([xshift=1cm]pre-processing.east) |- ([xshift=1cm]trainedmodel.east) -- (trainedmodel);
\end{tikzpicture}
\caption{Random Forest Classifier Flowchart for Multi-class CICIDS2017}\label{fig:RandomForestFlowMultiCICIDS2017}
\end{figure}

The multi-class CICIDS2017 dataset Random Forest Classifier experiment follows a similar process to the multi-class CICIDS2017 Dummy Classifier experiment (\ref{subsec:DummyClassifierMultiCICIDS2017}), with the main difference being the use of the Random Forest algorithm for classification. The goal is to investigate if the Random Forest Classifier can learn patterns from various attack types in CICIDS2017 that are similar to botnet attacks in CTU13. We use the SHAP library to explain and evaluate the performance using the same metrics.

\section{Support Vector Machine Classifier}\label{sec:SVMClassifier}

\textbf{Purpose} The Support Vector Machine (SVM) Classifier is a widely used algorithm in intrusion detection tasks~\cite{cortes1995support, scholkopf2002learning}. SVM aims to find the optimal hyperplane that maximally separates different classes in a high-dimensional feature space. It can handle both linear and non-linear classification tasks using kernel functions and is known for its ability to generalise well, even with limited training data~\cite{kim2003network, teng2017svm}.

\subsection{CTU13}\label{subsec:SVMClassifierCTU13}
\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
\node (dataset1) [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black] {CTU13 Dataset};
\node (pre-processing) [rectangle, draw, below=of dataset1] {Pre-processing(Binary)};
\node (SVM) [rectangle, draw, below=of pre-processing] {SVM Classifier};
\node (trainedmodel) [rectangle, draw, below=of SVM] {Trained Model};
\node (shap) [rectangle, draw, below=of trainedmodel] {SHAP};
\node (evaluation) [rectangle, rounded corners, text centered, draw=black, below=of shap] {Evaluation};

\draw [->] (dataset1) -- (pre-processing);
\draw [->] (pre-processing) -- node[anchor=east] {Training Data (60\%)} (SVM);
\draw [->] (SVM) -- (trainedmodel);
\draw [->] (trainedmodel) -- (shap);
\draw [->] (shap) -- (evaluation);
\draw [->] (pre-processing) -- node[anchor=south, xshift=1cm] {Testing Data (40\%)} ([xshift=1cm]pre-processing.east) |- ([xshift=1cm]trainedmodel.east) -- (trainedmodel);
\end{tikzpicture}
\caption{SVM Classifier Flowchart for CTU13}\label{fig:SVMFlowCTU13}
\end{figure}

The SVM Classifier experiment on the CTU13 dataset follows a similar process to the Random Forest Classifier experiment on the CTU13 dataset (\ref{subsec:RandomForestClassifierCTU13}), with the main difference being the use of the SVM algorithm for classification. The pre-processing steps, training and testing data split, and evaluation metrics remain the same. We also use the SHAP library to explain the classifier's predictions.

\subsection{Binary CICIDS2017}\label{subsec:SVMClassifierBinaryCICIDS2017}
\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
\node (dataset1) [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black] {CICIDS2017 Dataset};
\node (pre-processing) [rectangle, draw, below=of dataset1] {Pre-processing (Binary)};
\node (SVM) [rectangle, draw, below=of pre-processing] {SVM Classifier};
\node (trainedmodel) [rectangle, draw, below=of SVM] {Trained Model};
\node (shap) [rectangle, draw, below=of trainedmodel] {SHAP};
\node (evaluation) [rectangle, rounded corners, text centered, draw=black, below=of shap] {Evaluation};

\draw [->] (dataset1) -- (pre-processing);
\draw [->] (pre-processing) -- node[anchor=east] {Training Data (60\%)} (SVM);
\draw [->] (SVM) -- (trainedmodel);
\draw [->] (trainedmodel) -- (shap);
\draw [->] (shap) -- (evaluation);
\draw [->] (pre-processing) -- node[anchor=south, xshift=1cm] {Testing Data (40\%)} ([xshift=1cm]pre-processing.east) |- ([xshift=1cm]trainedmodel.east) -- (trainedmodel);
\end{tikzpicture}
\caption{SVM Classifier Flowchart for Binary CICIDS2017}\label{fig:SVMFlowBinaryCICIDS2017}
\end{figure}

The SVM Classifier experiment on the binary CICIDS2017 dataset is similar to the Random Forest Classifier experiment on the binary CICIDS2017 dataset (\ref{subsec:RandomForestBinaryCICIDS2017}), with the main difference being the use of the SVM algorithm for classification. The pre-processing steps, training and testing data split, and evaluation metrics remain the same. We also use the SHAP library to explain the classifier's predictions.

\subsection{Multi-class CICIDS2017}\label{subsec:SVMClassifierMultiCICIDS2017}
\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.5cm]
\node (dataset1) [trapezium, trapezium left angle=70, trapezium right angle=110, text centered, draw=black] {CICIDS2017 Dataset};
\node (pre-processing) [rectangle, draw, below=of dataset1] {Pre-processing (Multi-class)};
\node (SVM) [rectangle, draw, below=of pre-processing] {SVM Classifier};
\node (trainedmodel) [rectangle, draw, below=of SVM] {Trained Model};
\node (shap) [rectangle, draw, below=of trainedmodel] {SHAP};
\node (evaluation) [rectangle, rounded corners, text centered, draw=black, below=of shap] {Evaluation};

\draw [->] (dataset1) -- (pre-processing);
\draw [->] (pre-processing) -- node[anchor=east] {Training Data (60\%)} (SVM);
\draw [->] (SVM) -- (trainedmodel);
\draw [->] (trainedmodel) -- (shap);
\draw [->] (shap) -- (evaluation);
\draw [->] (pre-processing) -- node[anchor=south, xshift=1cm] {Testing Data (40\%)} ([xshift=1cm]pre-processing.east) |- ([xshift=1cm]trainedmodel.east) -- (trainedmodel);
\end{tikzpicture}
\caption{SVM Classifier Flowchart for Multi-class CICIDS2017}\label{fig:SVMFlowMultiCICIDS2017}
\end{figure}

The SVM Classifier experiment on the multi-class CICIDS2017 dataset mirrors the process employed in the Random Forest Classifier experiment on the same dataset (\ref{subsec:RandomForestMultiCICIDS2017}), with the main difference being the use of the SVM algorithm for classification. The objective is to investigate whether the SVM Classifier can detect resemblances in the flow structures of different attack categories in CICIDS2017 and botnet attacks in CTU13. We use the SHAP library to explain the most relevant features and rely on the same performance metrics for evaluation.