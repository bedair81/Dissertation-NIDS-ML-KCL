\chapter{Background}

Section~\ref{sec:datasets} provides an overview of two widely used datasets in the field of network intrusion detection: the CTU13 dataset~\cite{garcia2014empirical} and the CICIDS2017 dataset~\cite{sharafaldin2018toward}. These datasets have been extensively utilised by researchers to develop and evaluate machine learning-based NIDS.\@Understanding the characteristics, strengths, and limitations of these datasets is essential for designing robust and effective intrusion detection systems.

Section~\ref{sec:classifiers} discusses two popular machine learning classifiers, Random Forest and Support Vector Machine, which have been widely used in network intrusion detection systems. The strengths and limitations of these classifiers are highlighted, along with their performance on different datasets. Understanding the capabilities and trade-offs of these classifiers is crucial for selecting appropriate models for intrusion detection.

Section~\ref{sec:explainable} introduces explainable AI techniques, which aim to provide insights into the decision-making process of machine learning models. These techniques help in understanding the factors that contribute to the predictions made by the models and provide interpretable explanations for their outputs. Understanding the importance of explainable AI techniques is essential for validating the reliability of machine learning models and gaining insights into their decision-making process.

\section{CTU13 and CICIDS2017 Datasets}\label{sec:datasets}

The availability of representative and labeled datasets is crucial for developing and evaluating machine learning-based network intrusion detection systems. Two widely used benchmark datasets in this domain are the CTU13 dataset~\cite{garcia2014empirical} and the CICIDS2017 dataset~\cite{sharafaldin2018toward}.

Garcia et al.~\cite{garcia2014empirical} introduced the CTU13 dataset, which contains real botnet traffic captured in a controlled environment. The dataset consists of 13 scenarios, each representing specific botnet behaviors such as port scanning, DDoS attacks, click fraud, and spam. The authors provide a detailed description of the dataset creation methodology, including the setup of the controlled environment, the use of real botnet samples, and the labeling process based on the known behavior of the captured botnets. They also present an evaluation of the dataset using various machine learning algorithms, demonstrating its utility for botnet detection research. The realistic nature of the CTU13 dataset and the variety of botnet scenarios it covers have made it a popular choice among researchers.

Sharafaldin et al.~\cite{sharafaldin2018toward} created the CICIDS2017 dataset, which is a more recent and comprehensive dataset designed for evaluating network intrusion detection systems. The dataset contains a wide range of modern attacks, including DoS, DDoS, brute force, XSS, SQL injection, and infiltration. The authors provide a detailed description of the dataset generation process, which involved creating a controlled lab environment that closely resembles a real-world network infrastructure. They used various tools and scripts to generate realistic benign traffic and attack scenarios. The dataset also includes a combination of manually labeled and time-based labeled data. The authors evaluate the dataset using different machine learning algorithms and demonstrate its effectiveness in detecting various types of attacks.

Several studies have utiliased these datasets for developing and evaluating network intrusion detection systems. Chowdhury et al.~\cite{chowdhury2017botnet} proposed a graph-based approach for botnet detection using the CTU13 dataset. They constructed a graph representation of the communication patterns among botnet-infected hosts and applied graph analysis techniques to identify botnets. Their approach achieved high accuracy in detecting botnets and demonstrated the potential of leveraging graph-based features for botnet detection.

Pekta≈ü and Acarman~\cite{pektacs2019deep} applied deep learning techniques to the CTU13 dataset for botnet detection. They used a convolutional neural network (CNN) to learn discriminative features from raw network traffic data. Their proposed model achieved high detection accuracy and showcased the effectiveness of deep learning in capturing complex patterns and behaviors associated with botnets.

Ustebay et al.~\cite{ustebay2018intrusion} proposed an intrusion detection system based on a multi-layer perceptron (MLP) classifier using the CICIDS2017 dataset. They performed extensive preprocessing and feature selection to optimise the input data for the MLP classifier. Their approach achieved high detection accuracy for various attack types present in the dataset, demonstrating the potential of neural network-based models for network intrusion detection.

Aksu and Aydin~\cite{aksu2018detecting} conducted a comparative study of different machine learning algorithms for network intrusion detection using the CICIDS2017 dataset. They evaluated the performance of decision trees, random forests, and support vector machines. Their results showed that random forests outperformed other algorithms in terms of accuracy and false positive rates, highlighting the effectiveness of ensemble learning methods for intrusion detection.

While these studies demonstrate the utility of the CTU13 and CICIDS2017 datasets, it is important to acknowledge their limitations. Sommer and Paxson~\cite{sommer2010outside} discuss the challenges of using synthetic datasets for network intrusion detection. They argue that synthetic datasets may not fully capture the complexity and diversity of real-world network traffic and may lack important contextual information. They emphasise the need for more realistic and representative datasets that consider the operational aspects and deployment challenges of intrusion detection systems.

To address these limitations, Lashkari et al.~\cite{lashkari2017characterization} proposed a framework for generating representative network traffic datasets. Their approach incorporates techniques for generating realistic benign traffic and modeling user behavior to ensure the diversity and representativeness of the datasets. They also developed the CICFlowMeter tool, which enables the extraction of flow-based features from raw network traffic captures. This tool has been widely used in conjunction with the CICIDS2017 dataset for feature extraction and analysis.

However, Engelen et al.~\cite{engelen2021troubleshooting} identified limitations and issues in the CICFlowMeter tool that affect the quality of the extracted features in the CICIDS2017 dataset. They conducted an in-depth analysis of the dataset and discovered problems related to flow construction, feature extraction, and labeling. They proposed improvements to the CICFlowMeter tool and generated a revised version of the dataset to address these limitations, enhancing the reliability and utility of the dataset for intrusion detection research.

The importance of using representative and unbiased datasets for training machine learning models in network intrusion detection is emphasised by Sommer and Paxson~\cite{sommer2010outside}. They highlight the challenges posed by the dynamic nature of network traffic and the constant evolution of attack patterns, which can impact the long-term performance of the trained models. Buczak and Guven~\cite{buczak2015survey} provide a comprehensive survey of machine learning and data mining methods for cyber security intrusion detection. They discuss the considerations and challenges in applying machine learning techniques to network intrusion detection, including the selection of appropriate algorithms, feature engineering, and model evaluation.

\section{Machine Learning Classifiers}\label{sec:classifiers}

Machine learning classifiers have been widely used in network intrusion detection systems to automatically identify malicious activities and distinguish them from benign traffic. Random Forest (RF) and Support Vector Machine (SVM) are two popular classifiers that have shown promising results in this domain.

Random Forest is an ensemble learning method that combines multiple decision trees to make predictions~\cite{hastie2009random}. It constructs a large number of decision trees during the training phase and outputs the majority vote of the individual trees for classification tasks. Random Forest has advantages such as handling high-dimensional data, robustness to noise and outliers, and capturing complex interactions among features.

Farnaaz and Jabbar~\cite{farnaaz2016random} proposed a Random Forest-based model for intrusion detection and evaluated its performance on the NSL-KDD dataset. They performed feature selection using the Chi-square test and trained the Random Forest classifier on the selected features. Their model achieved an accuracy of 99.67\% and a low false positive rate of 0.06\%, demonstrating the effectiveness of Random Forest in detecting various types of network attacks.

Belouch et al.~\cite{belouch2018performance} applied Random Forest to the CICIDS2017 dataset for network intrusion detection. They compared the performance of Random Forest with other machine learning algorithms, including Decision Tree, Naive Bayes, and k-Nearest Neighbors. Their results showed that Random Forest outperformed other algorithms, achieving an accuracy of 99.98\% and a false positive rate of 0.01\%. They also analysed the importance of different features in the dataset and identified the most discriminative features for intrusion detection.

Support Vector Machine (SVM) is another widely used classifier in network intrusion detection. SVM aims to find the optimal hyperplane that maximally separates different classes in a high-dimensional feature space~\cite{cortes1995support}. It can handle both linear and non-linear classification tasks using kernel functions. SVM is known for its ability to generalise well, even with limited training data, making it suitable for network intrusion detection scenarios where labeled data may be scarce.

Kabir et al.~\cite{kabir2017network} proposed an SVM-based intrusion detection system and evaluated its performance on the NSL-KDD dataset. They used a genetic algorithm for feature selection and optimised the SVM parameters using grid search. Their proposed system achieved an accuracy of 99.91\% and a detection rate of 99.93\%, showcasing the effectiveness of SVM in detecting various types of network attacks.

Teng et al.~\cite{teng2017svm} applied SVM with different kernel functions for intrusion detection on the CICIDS2017 dataset. They compared the performance of linear, polynomial, and radial basis function (RBF) kernels. Their results showed that the RBF kernel achieved the highest accuracy of 97.80\% and a low false positive rate of 0.12\%. They also highlighted the importance of selecting appropriate kernel functions and tuning the SVM parameters for optimal performance.

The choice of machine learning classifier depends on various factors, such as the characteristics of the dataset, the nature of the attacks, and the computational resources available. Buczak and Guven~\cite{buczak2015survey} provide a comprehensive survey of machine learning methods for cyber security intrusion detection. They discuss the strengths and limitations of different classifiers and emphasise the importance of selecting appropriate features, handling imbalanced data, and evaluating the performance of classifiers using relevant metrics.

Comparing the performance of different classifiers on multiple datasets provides valuable insights into their generalisation capabilities and transferability. Training classifiers on one dataset and testing them on another helps assess how well the learned patterns and features can be applied to detect intrusions in different network environments. This approach helps in understanding the robustness and adaptability of the classifiers across various scenarios.

\section{Explainable AI Techniques}\label{sec:explainable}

While machine learning classifiers have shown promising results in network intrusion detection, their decision-making process is often considered a `black box', lacking transparency and interpretability. Explainable AI techniques aim to bridge this gap by providing insights into the reasoning behind the predictions made by these models.

SHAP (SHapley Additive exPlanations)~\cite{lundberg2017unified} is a popular technique for model interpretation. It is based on the concept of Shapley values from cooperative game theory and provides a unified framework for explaining the output of any machine learning model. SHAP assigns importance scores to each feature, indicating their contribution to the model's prediction for a specific instance. By applying SHAP to trained classifiers, researchers can identify the key features that contribute to the detection of specific types of attacks.

Warnecke et al.~\cite{warnecke2020evaluating} evaluated various explanation methods, including SHAP, for deep learning-based intrusion detection systems. They applied SHAP to a convolutional neural network (CNN) trained on the NSL-KDD dataset and analysed the importance of different features in the model's predictions. They demonstrated that SHAP can provide meaningful insights into the decision-making process of deep learning models and help identify the most influential features for detecting specific attack types.

Amarasinghe et al.~\cite{amarasinghe2018toward} employed SHAP to interpret the predictions of a deep learning-based NIDS.\@They trained a deep neural network on the NSL-KDD dataset and applied SHAP to explain the model's predictions. They analysed the SHAP values to understand the impact of different features on the model's decisions and identified the most discriminative features for detecting specific types of attacks. Their study highlights the potential of SHAP in providing interpretable explanations for deep learning-based NIDS.\@

Mane and Rao~\cite{mane2021explaining} used SHAP to explain the predictions of a random forest classifier for network intrusion detection. They trained the classifier on the NSL-KDD dataset and applied SHAP to interpret the model's predictions. They visualised the SHAP values to understand the contribution of each feature towards the model's output and identified the most important features for detecting various types of network attacks. Their study demonstrates the effectiveness of SHAP in providing interpretable explanations for ensemble learning methods like random forests.

The insights gained from explainable AI techniques can aid in validating the reliability of the trained models, identifying potential biases or limitations in the datasets, and guiding future improvements in feature engineering and model development. Moreover, these insights can be valuable for network security analysts and practitioners in understanding the key factors contributing to the detection of specific attacks and developing more targeted defense strategies.