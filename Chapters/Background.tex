\chapter{Background}\label{chap:background}

This chapter provides essential context for understanding the datasets, machine learning classifiers, and explainable AI techniques used in this dissertation. Section~\ref{sec:datasets} overviews two benchmark datasets in network intrusion detection: CTU13~\cite{garcia2014empirical} and CICIDS2017~\cite{sharafaldin2018toward}. These datasets are widely employed to develop and evaluate machine learning-based Network Intrusion Detection Systems (NIDS). Understanding their characteristics, strengths, and limitations is crucial for designing robust and effective NIDS.

Section~\ref{sec:classifiers} discusses two prominent machine learning classifiers—Random Forest and Support Vector Machine (SVM)—commonly used in NIDS. Their strengths, limitations, and performance across different datasets are examined, highlighting the importance of selecting appropriate models for intrusion detection tasks.

Section~\ref{sec:explainable} introduces explainable AI techniques, focusing on SHAP (SHapley Additive exPlanations)~\cite{lundberg2017unified}, which provides insights into the decision-making processes of machine learning models. These techniques are vital for validating model reliability and understanding the features that influence predictions of benign or malicious network flows.

\section{CTU13 and CICIDS2017 Datasets}\label{sec:datasets}

Representative and labelled datasets are fundamental for developing and evaluating machine learning-based NIDS. The CTU13~\cite{garcia2014empirical} and CICIDS2017~\cite{sharafaldin2018toward} datasets are two widely used benchmarks in this domain.

The CTU13 dataset, introduced by Garcia et al.~\cite{garcia2014empirical}, comprises real botnet traffic captured in a controlled environment. It includes 13 scenarios, each representing distinct botnet behaviours such as port scanning, DDoS attacks, click fraud, and spam. The dataset’s creation involved a detailed methodology, including the use of actual botnet samples and a labelling process based on known botnet behaviour. Its realistic nature and diverse botnet scenarios have made it a popular choice among researchers. Table~\ref{tab:ctu13_breakdown} presents the class distribution in CTU13.

\begin{table}[ht]
    \centering
    \begin{tabular}{lc}
    \toprule
    \textbf{Class} & \textbf{Count} \\
    \midrule
    Benign & 213,326 \\
    Botnet & 15,559 \\
    \bottomrule
    \end{tabular}
    \caption{CTU13 Dataset Class Breakdown}\label{tab:ctu13_breakdown}
\end{table}

Sharafaldin et al.~\cite{sharafaldin2018toward} developed the CICIDS2017 dataset, a more recent and comprehensive resource for evaluating NIDS. It encompasses a variety of modern attacks, including DoS, DDoS, brute force, XSS, SQL injection, and infiltration. The dataset was generated in a controlled lab environment that mimics real-world network infrastructure, using tools and scripts to create realistic benign and attack traffic. It features both manually and time-based labelled data, as shown in Table~\ref{tab:cicids2017_breakdown}.

\begin{table}[ht]
    \centering
    \begin{tabular}{lr}
    \toprule
    \textbf{Class} & \textbf{Count} \\
    \midrule
    Benign & 908,528 \\
    Botnet & 745 \\
    DDoS & 51,234 \\
    DoS GoldenEye & 4,189 \\
    DoS Hulk & 91,856 \\
    DoS Slowhttptest & 2,191 \\
    DoS slowloris & 2,355 \\
    FTP-Patator & 3,184 \\
    Heartbleed & 6 \\
    Infiltration & 18 \\
    PortScan & 63,633 \\
    SSH-Patator & 2,342 \\
    Web Attack Brute Force & 601 \\
    Web Attack SQL Injection & 9 \\
    Web Attack XSS & 260 \\
    \bottomrule
    \end{tabular}
    \caption{CICIDS2017 Dataset Class Breakdown}\label{tab:cicids2017_breakdown}
\end{table}

Comparing the datasets, botnet attacks in CTU13 share structural and behavioural similarities with several attack types in CICIDS2017, such as DDoS/DoS, web attacks, and bot attacks. These similarities suggest that machine learning models trained on CICIDS2017 may be transferable to detecting botnet attacks in CTU13. However, both datasets have limitations: synthetic datasets like CICIDS2017 may not fully capture the complexity and diversity of real-world traffic, lacking crucial contextual information. More representative datasets that reflect operational and deployment challenges are needed to fully assess machine learning-based NIDS.

\section{Machine Learning Classifiers}\label{sec:classifiers}

Machine learning classifiers are integral to NIDS, automating the distinction between malicious and benign traffic. Random Forest (RF) and Support Vector Machine (SVM) are two widely adopted classifiers in this domain due to their effectiveness in handling complex, high-dimensional data.

Random Forest, an ensemble method, combines multiple decision trees to produce a majority-vote classification~\cite{hastie2009random}. Its strengths include handling high-dimensional data, robustness to noise and outliers, and the ability to model complex feature interactions—key advantages for detecting diverse network intrusions.

Support Vector Machine (SVM) identifies the optimal hyperplane to separate classes in high-dimensional space~\cite{cortes1995support}. It excels in scenarios with limited labelled data, a common challenge in NIDS, and can manage both linear and non-linear classification tasks via kernel functions. SVM’s strong generalisation capabilities make it suitable for detecting novel attacks.

The selection of a classifier depends on factors such as dataset characteristics, attack types, and computational resources. Evaluating classifiers using metrics like accuracy, precision, and recall is essential for choosing the most effective model for intrusion detection.

\section{Explainable AI Techniques}\label{sec:explainable}

Despite their success, machine learning classifiers often operate as `black boxes,' offering limited insight into their decision-making processes. Explainable AI techniques address this by providing interpretable explanations for model predictions.

SHAP (SHapley Additive exPlanations)~\cite{lundberg2017unified} is a leading technique for model interpretation, rooted in cooperative game theory. It assigns importance scores to each feature, quantifying their contribution to a model’s prediction for a given instance. In the context of NIDS, SHAP helps identify key features that influence the detection of specific attacks, enhancing transparency and trust in the model’s outputs.

Insights from SHAP can validate model reliability, uncover dataset biases, and inform feature engineering. For network security practitioners, these explanations are invaluable for understanding the factors driving attack detection and refining defence strategies.